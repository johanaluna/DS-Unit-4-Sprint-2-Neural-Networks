diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index 7e1d510..e177aa5 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -71,7 +71,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -96,7 +96,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
@@ -177,161 +177,161 @@
      "text": [
       "Train on 404 samples, validate on 102 samples\n",
       "Epoch 1/75\n",
-      "404/404 [==============================] - 2s 4ms/sample - loss: 498.2045 - mse: 498.2046 - mae: 20.2543 - val_loss: 421.5039 - val_mse: 421.5038 - val_mae: 18.3349\n",
+      "404/404 [==============================] - 1s 3ms/sample - loss: 493.6933 - mse: 493.6934 - mae: 20.2599 - val_loss: 401.1090 - val_mse: 401.1090 - val_mae: 18.0255\n",
       "Epoch 2/75\n",
-      "404/404 [==============================] - 0s 347us/sample - loss: 249.6985 - mse: 249.6985 - mae: 13.2672 - val_loss: 111.3743 - val_mse: 111.3743 - val_mae: 8.6210\n",
+      "404/404 [==============================] - 0s 367us/sample - loss: 237.6896 - mse: 237.6895 - mae: 12.8030 - val_loss: 113.6937 - val_mse: 113.6937 - val_mae: 8.9075\n",
       "Epoch 3/75\n",
-      "404/404 [==============================] - 0s 344us/sample - loss: 56.6755 - mse: 56.6755 - mae: 5.4817 - val_loss: 39.1997 - val_mse: 39.1997 - val_mae: 4.9872\n",
+      "404/404 [==============================] - 0s 355us/sample - loss: 69.1703 - mse: 69.1703 - mae: 6.1513 - val_loss: 49.7945 - val_mse: 49.7945 - val_mae: 5.4479\n",
       "Epoch 4/75\n",
-      "404/404 [==============================] - 0s 364us/sample - loss: 28.3243 - mse: 28.3243 - mae: 3.7054 - val_loss: 26.9866 - val_mse: 26.9866 - val_mae: 4.0796\n",
+      "404/404 [==============================] - 0s 351us/sample - loss: 34.2402 - mse: 34.2402 - mae: 4.2268 - val_loss: 32.3961 - val_mse: 32.3961 - val_mae: 4.5050\n",
       "Epoch 5/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 20.5281 - mse: 20.5281 - mae: 3.1209 - val_loss: 24.6172 - val_mse: 24.6172 - val_mae: 3.8052\n",
+      "404/404 [==============================] - 0s 339us/sample - loss: 24.5330 - mse: 24.5330 - mae: 3.5526 - val_loss: 26.9019 - val_mse: 26.9019 - val_mae: 4.0517\n",
       "Epoch 6/75\n",
-      "404/404 [==============================] - 0s 393us/sample - loss: 17.9283 - mse: 17.9283 - mae: 2.8665 - val_loss: 23.6524 - val_mse: 23.6524 - val_mae: 3.6746\n",
+      "404/404 [==============================] - 0s 368us/sample - loss: 20.3231 - mse: 20.3231 - mae: 3.1693 - val_loss: 24.8196 - val_mse: 24.8196 - val_mae: 3.8670\n",
       "Epoch 7/75\n",
-      "404/404 [==============================] - 0s 440us/sample - loss: 16.9179 - mse: 16.9179 - mae: 2.8781 - val_loss: 23.4620 - val_mse: 23.4620 - val_mae: 3.5778\n",
+      "404/404 [==============================] - 0s 359us/sample - loss: 18.1235 - mse: 18.1235 - mae: 3.0447 - val_loss: 23.4254 - val_mse: 23.4254 - val_mae: 3.6660\n",
       "Epoch 8/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 15.1579 - mse: 15.1579 - mae: 2.6440 - val_loss: 24.1374 - val_mse: 24.1374 - val_mae: 3.5929\n",
+      "404/404 [==============================] - 0s 355us/sample - loss: 16.2702 - mse: 16.2702 - mae: 2.8503 - val_loss: 22.1186 - val_mse: 22.1186 - val_mae: 3.4900\n",
       "Epoch 9/75\n",
-      "404/404 [==============================] - 0s 367us/sample - loss: 14.1717 - mse: 14.1717 - mae: 2.5937 - val_loss: 24.4829 - val_mse: 24.4829 - val_mae: 3.5639\n",
+      "404/404 [==============================] - 0s 354us/sample - loss: 14.7918 - mse: 14.7918 - mae: 2.7264 - val_loss: 22.6100 - val_mse: 22.6100 - val_mae: 3.4310\n",
       "Epoch 10/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 13.5002 - mse: 13.5002 - mae: 2.5633 - val_loss: 25.0170 - val_mse: 25.0170 - val_mae: 3.5601\n",
+      "404/404 [==============================] - 0s 345us/sample - loss: 13.6529 - mse: 13.6529 - mae: 2.6085 - val_loss: 22.6931 - val_mse: 22.6931 - val_mae: 3.4357\n",
       "Epoch 11/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.8641 - mse: 12.8641 - mae: 2.4963 - val_loss: 25.1162 - val_mse: 25.1162 - val_mae: 3.5449\n",
+      "404/404 [==============================] - 0s 367us/sample - loss: 12.9722 - mse: 12.9722 - mae: 2.5643 - val_loss: 21.2874 - val_mse: 21.2874 - val_mae: 3.2651\n",
       "Epoch 12/75\n",
-      "404/404 [==============================] - 0s 351us/sample - loss: 12.4033 - mse: 12.4033 - mae: 2.5224 - val_loss: 25.0382 - val_mse: 25.0382 - val_mae: 3.4858\n",
+      "404/404 [==============================] - 0s 359us/sample - loss: 12.0795 - mse: 12.0795 - mae: 2.4869 - val_loss: 21.5838 - val_mse: 21.5838 - val_mae: 3.2397\n",
       "Epoch 13/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.2653 - mse: 12.2653 - mae: 2.4637 - val_loss: 26.7274 - val_mse: 26.7274 - val_mae: 3.6054\n",
+      "404/404 [==============================] - 0s 362us/sample - loss: 11.6166 - mse: 11.6166 - mae: 2.4449 - val_loss: 22.0905 - val_mse: 22.0905 - val_mae: 3.2360\n",
       "Epoch 14/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 11.8249 - mse: 11.8249 - mae: 2.4648 - val_loss: 25.2347 - val_mse: 25.2347 - val_mae: 3.4602\n",
+      "404/404 [==============================] - 0s 376us/sample - loss: 11.1296 - mse: 11.1296 - mae: 2.3849 - val_loss: 21.7581 - val_mse: 21.7581 - val_mae: 3.2227\n",
       "Epoch 15/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 11.3965 - mse: 11.3965 - mae: 2.4134 - val_loss: 25.3070 - val_mse: 25.3070 - val_mae: 3.4305\n",
+      "404/404 [==============================] - 0s 337us/sample - loss: 10.8171 - mse: 10.8171 - mae: 2.3820 - val_loss: 23.6956 - val_mse: 23.6956 - val_mae: 3.2928\n",
       "Epoch 16/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 11.0982 - mse: 11.0982 - mae: 2.3616 - val_loss: 25.0599 - val_mse: 25.0599 - val_mae: 3.3784\n",
+      "404/404 [==============================] - 0s 334us/sample - loss: 10.5791 - mse: 10.5791 - mae: 2.3634 - val_loss: 22.3192 - val_mse: 22.3192 - val_mae: 3.1481\n",
       "Epoch 17/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 11.1969 - mse: 11.1969 - mae: 2.3806 - val_loss: 25.1976 - val_mse: 25.1976 - val_mae: 3.3732\n",
+      "404/404 [==============================] - 0s 338us/sample - loss: 10.5367 - mse: 10.5367 - mae: 2.3467 - val_loss: 23.2535 - val_mse: 23.2535 - val_mae: 3.2832\n",
       "Epoch 18/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 10.9278 - mse: 10.9278 - mae: 2.3653 - val_loss: 24.2875 - val_mse: 24.2875 - val_mae: 3.3114\n",
+      "404/404 [==============================] - 0s 349us/sample - loss: 10.1464 - mse: 10.1464 - mae: 2.3121 - val_loss: 23.6119 - val_mse: 23.6119 - val_mae: 3.2699\n",
       "Epoch 19/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 10.5854 - mse: 10.5854 - mae: 2.3170 - val_loss: 26.1450 - val_mse: 26.1450 - val_mae: 3.3971\n",
+      "404/404 [==============================] - 0s 359us/sample - loss: 9.8155 - mse: 9.8155 - mae: 2.2901 - val_loss: 22.5401 - val_mse: 22.5401 - val_mae: 3.1464\n",
       "Epoch 20/75\n",
-      "404/404 [==============================] - 0s 401us/sample - loss: 10.2546 - mse: 10.2546 - mae: 2.2813 - val_loss: 26.5278 - val_mse: 26.5278 - val_mae: 3.4465\n",
+      "404/404 [==============================] - 0s 355us/sample - loss: 9.6659 - mse: 9.6659 - mae: 2.2372 - val_loss: 22.8756 - val_mse: 22.8756 - val_mae: 3.1968\n",
       "Epoch 21/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 10.1321 - mse: 10.1321 - mae: 2.2866 - val_loss: 24.0363 - val_mse: 24.0363 - val_mae: 3.2792\n",
+      "404/404 [==============================] - 0s 364us/sample - loss: 9.4889 - mse: 9.4889 - mae: 2.2256 - val_loss: 22.0853 - val_mse: 22.0853 - val_mae: 3.1516\n",
       "Epoch 22/75\n",
-      "404/404 [==============================] - 0s 421us/sample - loss: 9.9169 - mse: 9.9169 - mae: 2.2907 - val_loss: 23.7310 - val_mse: 23.7310 - val_mae: 3.2334\n",
+      "404/404 [==============================] - 0s 340us/sample - loss: 9.1463 - mse: 9.1463 - mae: 2.2271 - val_loss: 21.9462 - val_mse: 21.9462 - val_mae: 3.1011\n",
       "Epoch 23/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.6588 - mse: 9.6588 - mae: 2.2284 - val_loss: 23.6472 - val_mse: 23.6472 - val_mae: 3.2013\n",
+      "404/404 [==============================] - 0s 342us/sample - loss: 9.0568 - mse: 9.0568 - mae: 2.1834 - val_loss: 22.3112 - val_mse: 22.3112 - val_mae: 3.0882\n",
       "Epoch 24/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 9.6887 - mse: 9.6887 - mae: 2.2468 - val_loss: 23.5379 - val_mse: 23.5379 - val_mae: 3.1921\n",
+      "404/404 [==============================] - 0s 345us/sample - loss: 9.0247 - mse: 9.0247 - mae: 2.1665 - val_loss: 21.5197 - val_mse: 21.5197 - val_mae: 2.9951\n",
       "Epoch 25/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 9.4049 - mse: 9.4049 - mae: 2.1999 - val_loss: 23.7713 - val_mse: 23.7713 - val_mae: 3.2273\n",
+      "404/404 [==============================] - 0s 351us/sample - loss: 9.5031 - mse: 9.5031 - mae: 2.2412 - val_loss: 21.0716 - val_mse: 21.0716 - val_mae: 2.9585\n",
       "Epoch 26/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 9.2304 - mse: 9.2304 - mae: 2.1946 - val_loss: 23.5093 - val_mse: 23.5093 - val_mae: 3.2072\n",
+      "404/404 [==============================] - 0s 355us/sample - loss: 8.5793 - mse: 8.5793 - mae: 2.1281 - val_loss: 21.1745 - val_mse: 21.1744 - val_mae: 3.0160\n",
       "Epoch 27/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.0493 - mse: 9.0493 - mae: 2.1528 - val_loss: 23.7969 - val_mse: 23.7969 - val_mae: 3.2005\n",
+      "404/404 [==============================] - 0s 364us/sample - loss: 8.3855 - mse: 8.3855 - mae: 2.0787 - val_loss: 20.5811 - val_mse: 20.5811 - val_mae: 2.9400\n",
       "Epoch 28/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 8.9363 - mse: 8.9363 - mae: 2.1475 - val_loss: 22.1030 - val_mse: 22.1030 - val_mae: 3.0707\n",
+      "404/404 [==============================] - 0s 373us/sample - loss: 8.3149 - mse: 8.3149 - mae: 2.0599 - val_loss: 20.9765 - val_mse: 20.9765 - val_mae: 2.9451\n",
       "Epoch 29/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 8.7834 - mse: 8.7834 - mae: 2.1231 - val_loss: 22.5153 - val_mse: 22.5153 - val_mae: 3.1532\n",
+      "404/404 [==============================] - 0s 351us/sample - loss: 8.0191 - mse: 8.0191 - mae: 2.0520 - val_loss: 20.8008 - val_mse: 20.8008 - val_mae: 2.8986\n",
       "Epoch 30/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.7925 - mse: 8.7925 - mae: 2.1531 - val_loss: 22.0449 - val_mse: 22.0449 - val_mae: 3.1245\n",
+      "404/404 [==============================] - 0s 352us/sample - loss: 7.8773 - mse: 7.8773 - mae: 2.0061 - val_loss: 21.4924 - val_mse: 21.4924 - val_mae: 3.0303\n",
       "Epoch 31/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 9.1879 - mse: 9.1879 - mae: 2.2029 - val_loss: 22.1780 - val_mse: 22.1780 - val_mae: 3.0623\n",
+      "404/404 [==============================] - 0s 336us/sample - loss: 8.0462 - mse: 8.0462 - mae: 2.0596 - val_loss: 20.5716 - val_mse: 20.5716 - val_mae: 2.9645\n",
       "Epoch 32/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.7136 - mse: 8.7136 - mae: 2.1164 - val_loss: 21.9815 - val_mse: 21.9815 - val_mae: 3.0969\n",
+      "404/404 [==============================] - 0s 342us/sample - loss: 7.7968 - mse: 7.7968 - mae: 2.0155 - val_loss: 22.1853 - val_mse: 22.1853 - val_mae: 3.0909\n",
       "Epoch 33/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.3018 - mse: 8.3018 - mae: 2.0639 - val_loss: 21.0477 - val_mse: 21.0477 - val_mae: 2.9645\n",
+      "404/404 [==============================] - 0s 370us/sample - loss: 7.5105 - mse: 7.5105 - mae: 1.9563 - val_loss: 19.8208 - val_mse: 19.8208 - val_mae: 2.8799\n",
       "Epoch 34/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 8.4156 - mse: 8.4156 - mae: 2.0970 - val_loss: 22.6659 - val_mse: 22.6659 - val_mae: 3.1235\n",
+      "404/404 [==============================] - 0s 369us/sample - loss: 7.8275 - mse: 7.8275 - mae: 2.0209 - val_loss: 19.5335 - val_mse: 19.5335 - val_mae: 2.8711\n",
       "Epoch 35/75\n",
-      "404/404 [==============================] - 0s 350us/sample - loss: 8.2938 - mse: 8.2938 - mae: 2.0567 - val_loss: 20.9574 - val_mse: 20.9574 - val_mae: 2.9746\n",
+      "404/404 [==============================] - 0s 354us/sample - loss: 7.5972 - mse: 7.5972 - mae: 1.9760 - val_loss: 20.2413 - val_mse: 20.2413 - val_mae: 2.8624\n",
       "Epoch 36/75\n",
-      "404/404 [==============================] - 0s 357us/sample - loss: 8.0515 - mse: 8.0515 - mae: 2.0591 - val_loss: 23.2063 - val_mse: 23.2063 - val_mae: 3.1980\n",
+      "404/404 [==============================] - 0s 360us/sample - loss: 7.7007 - mse: 7.7007 - mae: 1.9945 - val_loss: 20.5972 - val_mse: 20.5972 - val_mae: 2.8700\n",
       "Epoch 37/75\n",
-      "404/404 [==============================] - 0s 381us/sample - loss: 8.1403 - mse: 8.1403 - mae: 2.0584 - val_loss: 24.5238 - val_mse: 24.5237 - val_mae: 3.3531\n",
+      "404/404 [==============================] - 0s 372us/sample - loss: 7.2596 - mse: 7.2596 - mae: 1.9308 - val_loss: 19.5516 - val_mse: 19.5516 - val_mae: 2.8682\n",
       "Epoch 38/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 8.0043 - mse: 8.0043 - mae: 2.0776 - val_loss: 22.5424 - val_mse: 22.5424 - val_mae: 3.1494\n",
+      "404/404 [==============================] - 0s 368us/sample - loss: 7.1538 - mse: 7.1538 - mae: 1.9387 - val_loss: 19.6646 - val_mse: 19.6646 - val_mae: 2.8987\n",
       "Epoch 39/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.1182 - mse: 8.1182 - mae: 2.0683 - val_loss: 19.7576 - val_mse: 19.7576 - val_mae: 2.8799\n",
+      "404/404 [==============================] - 0s 340us/sample - loss: 7.1916 - mse: 7.1916 - mae: 1.9447 - val_loss: 18.6375 - val_mse: 18.6375 - val_mae: 2.7918\n",
       "Epoch 40/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 7.8578 - mse: 7.8578 - mae: 2.0131 - val_loss: 20.7728 - val_mse: 20.7728 - val_mae: 2.9499\n",
+      "404/404 [==============================] - 0s 359us/sample - loss: 6.9026 - mse: 6.9026 - mae: 1.8659 - val_loss: 18.3142 - val_mse: 18.3142 - val_mae: 2.7041\n",
       "Epoch 41/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 7.5711 - mse: 7.5711 - mae: 1.9896 - val_loss: 20.6170 - val_mse: 20.6170 - val_mae: 2.9936\n",
+      "404/404 [==============================] - 0s 350us/sample - loss: 6.7294 - mse: 6.7294 - mae: 1.8692 - val_loss: 18.2883 - val_mse: 18.2883 - val_mae: 2.7791\n",
       "Epoch 42/75\n",
-      "404/404 [==============================] - 0s 385us/sample - loss: 7.5822 - mse: 7.5822 - mae: 1.9683 - val_loss: 20.8541 - val_mse: 20.8541 - val_mae: 3.0054\n",
+      "404/404 [==============================] - 0s 341us/sample - loss: 6.7355 - mse: 6.7355 - mae: 1.8722 - val_loss: 18.3284 - val_mse: 18.3284 - val_mae: 2.6973\n",
       "Epoch 43/75\n",
-      "404/404 [==============================] - 0s 408us/sample - loss: 7.4533 - mse: 7.4533 - mae: 1.9645 - val_loss: 20.4473 - val_mse: 20.4473 - val_mae: 2.8861\n",
+      "404/404 [==============================] - 0s 350us/sample - loss: 6.7899 - mse: 6.7899 - mae: 1.8582 - val_loss: 18.1757 - val_mse: 18.1757 - val_mae: 2.6755\n",
       "Epoch 44/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 7.5226 - mse: 7.5226 - mae: 1.9509 - val_loss: 20.5193 - val_mse: 20.5193 - val_mae: 2.9619\n",
+      "404/404 [==============================] - 0s 363us/sample - loss: 6.5563 - mse: 6.5563 - mae: 1.8311 - val_loss: 17.1175 - val_mse: 17.1175 - val_mae: 2.6358\n",
       "Epoch 45/75\n",
-      "404/404 [==============================] - 0s 355us/sample - loss: 7.2819 - mse: 7.2819 - mae: 1.9350 - val_loss: 21.4862 - val_mse: 21.4862 - val_mae: 2.9908\n",
+      "404/404 [==============================] - 0s 368us/sample - loss: 6.3481 - mse: 6.3481 - mae: 1.7912 - val_loss: 18.8515 - val_mse: 18.8515 - val_mae: 2.8750\n",
       "Epoch 46/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 7.0130 - mse: 7.0130 - mae: 1.9152 - val_loss: 20.1577 - val_mse: 20.1577 - val_mae: 2.9370\n",
+      "404/404 [==============================] - 0s 361us/sample - loss: 6.3317 - mse: 6.3317 - mae: 1.8141 - val_loss: 17.4340 - val_mse: 17.4340 - val_mae: 2.6862\n",
       "Epoch 47/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.9431 - mse: 6.9431 - mae: 1.8819 - val_loss: 21.1210 - val_mse: 21.1210 - val_mae: 2.9746\n",
+      "404/404 [==============================] - 0s 355us/sample - loss: 6.5919 - mse: 6.5919 - mae: 1.8157 - val_loss: 17.4449 - val_mse: 17.4449 - val_mae: 2.5877\n",
       "Epoch 48/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 6.8982 - mse: 6.8982 - mae: 1.9037 - val_loss: 19.2999 - val_mse: 19.2999 - val_mae: 2.8638\n",
+      "404/404 [==============================] - 0s 354us/sample - loss: 6.2146 - mse: 6.2146 - mae: 1.8086 - val_loss: 17.5619 - val_mse: 17.5619 - val_mae: 2.6570\n",
       "Epoch 49/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 6.9521 - mse: 6.9521 - mae: 1.8862 - val_loss: 20.7825 - val_mse: 20.7825 - val_mae: 2.9369\n",
+      "404/404 [==============================] - 0s 344us/sample - loss: 6.1634 - mse: 6.1634 - mae: 1.7579 - val_loss: 17.4918 - val_mse: 17.4918 - val_mae: 2.6999\n",
       "Epoch 50/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.8718 - mse: 6.8718 - mae: 1.8889 - val_loss: 20.0288 - val_mse: 20.0288 - val_mae: 2.8915\n",
+      "404/404 [==============================] - 0s 350us/sample - loss: 6.1885 - mse: 6.1885 - mae: 1.7933 - val_loss: 16.8926 - val_mse: 16.8926 - val_mae: 2.5757\n",
       "Epoch 51/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 6.7111 - mse: 6.7111 - mae: 1.8702 - val_loss: 20.4913 - val_mse: 20.4913 - val_mae: 3.0116\n",
+      "404/404 [==============================] - 0s 360us/sample - loss: 6.0296 - mse: 6.0296 - mae: 1.7717 - val_loss: 17.3799 - val_mse: 17.3799 - val_mae: 2.7137\n",
       "Epoch 52/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 6.7492 - mse: 6.7492 - mae: 1.8482 - val_loss: 18.3008 - val_mse: 18.3008 - val_mae: 2.7362\n",
+      "404/404 [==============================] - 0s 346us/sample - loss: 5.9737 - mse: 5.9737 - mae: 1.7303 - val_loss: 17.2564 - val_mse: 17.2564 - val_mae: 2.6183\n",
       "Epoch 53/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.6262 - mse: 6.6262 - mae: 1.8395 - val_loss: 18.1885 - val_mse: 18.1885 - val_mae: 2.6920\n",
+      "404/404 [==============================] - 0s 358us/sample - loss: 5.8863 - mse: 5.8863 - mae: 1.7526 - val_loss: 16.8502 - val_mse: 16.8502 - val_mae: 2.6611\n",
       "Epoch 54/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 6.7148 - mse: 6.7148 - mae: 1.8611 - val_loss: 18.5764 - val_mse: 18.5764 - val_mae: 2.6977\n",
+      "404/404 [==============================] - 0s 361us/sample - loss: 6.0973 - mse: 6.0973 - mae: 1.8019 - val_loss: 15.9202 - val_mse: 15.9202 - val_mae: 2.5313\n",
       "Epoch 55/75\n",
-      "404/404 [==============================] - 0s 358us/sample - loss: 6.5425 - mse: 6.5425 - mae: 1.8522 - val_loss: 19.5772 - val_mse: 19.5772 - val_mae: 2.8326\n",
+      "404/404 [==============================] - 0s 352us/sample - loss: 5.7930 - mse: 5.7930 - mae: 1.7141 - val_loss: 17.5795 - val_mse: 17.5795 - val_mae: 2.7775\n",
       "Epoch 56/75\n",
-      "404/404 [==============================] - 0s 423us/sample - loss: 6.3349 - mse: 6.3349 - mae: 1.8175 - val_loss: 19.0932 - val_mse: 19.0932 - val_mae: 2.8260\n",
+      "404/404 [==============================] - 0s 337us/sample - loss: 5.6881 - mse: 5.6881 - mae: 1.6919 - val_loss: 17.4284 - val_mse: 17.4284 - val_mae: 2.7201\n",
       "Epoch 57/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.4253 - mse: 6.4253 - mae: 1.7972 - val_loss: 20.4036 - val_mse: 20.4036 - val_mae: 2.9258\n",
+      "404/404 [==============================] - 0s 333us/sample - loss: 5.9356 - mse: 5.9356 - mae: 1.7747 - val_loss: 16.6772 - val_mse: 16.6772 - val_mae: 2.6365\n",
       "Epoch 58/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.2897 - mse: 6.2897 - mae: 1.7785 - val_loss: 21.2845 - val_mse: 21.2845 - val_mae: 3.0715\n",
+      "404/404 [==============================] - 0s 327us/sample - loss: 5.5241 - mse: 5.5241 - mae: 1.7129 - val_loss: 17.8799 - val_mse: 17.8799 - val_mae: 2.7848\n",
       "Epoch 59/75\n",
-      "404/404 [==============================] - 0s 378us/sample - loss: 6.7839 - mse: 6.7839 - mae: 1.9027 - val_loss: 18.6853 - val_mse: 18.6853 - val_mae: 2.7709\n",
+      "404/404 [==============================] - 0s 319us/sample - loss: 5.4682 - mse: 5.4682 - mae: 1.6721 - val_loss: 16.0718 - val_mse: 16.0718 - val_mae: 2.5231\n",
       "Epoch 60/75\n",
-      "404/404 [==============================] - 0s 395us/sample - loss: 6.7178 - mse: 6.7178 - mae: 1.8871 - val_loss: 19.5394 - val_mse: 19.5394 - val_mae: 2.8101\n",
+      "404/404 [==============================] - 0s 326us/sample - loss: 5.6889 - mse: 5.6889 - mae: 1.7276 - val_loss: 15.4723 - val_mse: 15.4723 - val_mae: 2.5238\n",
       "Epoch 61/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 6.4152 - mse: 6.4152 - mae: 1.8175 - val_loss: 18.2377 - val_mse: 18.2377 - val_mae: 2.7450\n",
+      "404/404 [==============================] - 0s 324us/sample - loss: 5.4246 - mse: 5.4246 - mae: 1.6654 - val_loss: 15.7677 - val_mse: 15.7677 - val_mae: 2.5381\n",
       "Epoch 62/75\n",
-      "404/404 [==============================] - 0s 384us/sample - loss: 5.9727 - mse: 5.9727 - mae: 1.7630 - val_loss: 19.0252 - val_mse: 19.0252 - val_mae: 2.7960\n",
+      "404/404 [==============================] - 0s 331us/sample - loss: 5.4090 - mse: 5.4090 - mae: 1.6892 - val_loss: 16.4156 - val_mse: 16.4156 - val_mae: 2.6113\n",
       "Epoch 63/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 6.0973 - mse: 6.0973 - mae: 1.8071 - val_loss: 18.8069 - val_mse: 18.8069 - val_mae: 2.8894\n",
+      "404/404 [==============================] - 0s 321us/sample - loss: 5.3137 - mse: 5.3137 - mae: 1.6237 - val_loss: 16.5213 - val_mse: 16.5213 - val_mae: 2.6502\n",
       "Epoch 64/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.1074 - mse: 6.1074 - mae: 1.7978 - val_loss: 18.4702 - val_mse: 18.4702 - val_mae: 2.7851\n",
+      "404/404 [==============================] - 0s 330us/sample - loss: 5.1647 - mse: 5.1647 - mae: 1.6444 - val_loss: 16.0742 - val_mse: 16.0742 - val_mae: 2.5474\n",
       "Epoch 65/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 5.9329 - mse: 5.9329 - mae: 1.7545 - val_loss: 18.5321 - val_mse: 18.5321 - val_mae: 2.7933\n",
+      "404/404 [==============================] - 0s 336us/sample - loss: 5.0975 - mse: 5.0975 - mae: 1.5983 - val_loss: 17.1582 - val_mse: 17.1582 - val_mae: 2.7853\n",
       "Epoch 66/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.7473 - mse: 5.7473 - mae: 1.7211 - val_loss: 18.5536 - val_mse: 18.5536 - val_mae: 2.8010\n",
+      "404/404 [==============================] - 0s 332us/sample - loss: 5.2878 - mse: 5.2878 - mae: 1.6593 - val_loss: 15.9717 - val_mse: 15.9717 - val_mae: 2.5503\n",
       "Epoch 67/75\n",
-      "404/404 [==============================] - 0s 339us/sample - loss: 5.8866 - mse: 5.8866 - mae: 1.7224 - val_loss: 18.0067 - val_mse: 18.0067 - val_mae: 2.7054\n",
+      "404/404 [==============================] - 0s 327us/sample - loss: 4.9298 - mse: 4.9298 - mae: 1.5903 - val_loss: 15.2181 - val_mse: 15.2181 - val_mae: 2.4766\n",
       "Epoch 68/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.7885 - mse: 5.7885 - mae: 1.7391 - val_loss: 17.5502 - val_mse: 17.5502 - val_mae: 2.6767\n",
+      "404/404 [==============================] - 0s 326us/sample - loss: 4.8663 - mse: 4.8663 - mae: 1.5787 - val_loss: 15.8968 - val_mse: 15.8968 - val_mae: 2.6216\n",
       "Epoch 69/75\n",
-      "404/404 [==============================] - 0s 331us/sample - loss: 5.8809 - mse: 5.8809 - mae: 1.7542 - val_loss: 17.0280 - val_mse: 17.0280 - val_mae: 2.6404\n",
+      "404/404 [==============================] - 0s 325us/sample - loss: 4.6781 - mse: 4.6781 - mae: 1.5440 - val_loss: 16.4577 - val_mse: 16.4577 - val_mae: 2.6829\n",
       "Epoch 70/75\n",
-      "404/404 [==============================] - 0s 343us/sample - loss: 5.6028 - mse: 5.6028 - mae: 1.6972 - val_loss: 17.7188 - val_mse: 17.7188 - val_mae: 2.6979\n",
+      "404/404 [==============================] - 0s 336us/sample - loss: 4.9005 - mse: 4.9005 - mae: 1.5972 - val_loss: 15.2383 - val_mse: 15.2383 - val_mae: 2.5272\n",
       "Epoch 71/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.4361 - mse: 5.4361 - mae: 1.6741 - val_loss: 16.8852 - val_mse: 16.8852 - val_mae: 2.6126\n",
+      "404/404 [==============================] - 0s 344us/sample - loss: 4.6089 - mse: 4.6089 - mae: 1.5511 - val_loss: 17.0117 - val_mse: 17.0117 - val_mae: 2.7602\n",
       "Epoch 72/75\n",
-      "404/404 [==============================] - 0s 345us/sample - loss: 5.5608 - mse: 5.5608 - mae: 1.7252 - val_loss: 16.7483 - val_mse: 16.7483 - val_mae: 2.6063\n",
+      "404/404 [==============================] - 0s 331us/sample - loss: 4.6398 - mse: 4.6398 - mae: 1.5587 - val_loss: 15.3959 - val_mse: 15.3959 - val_mae: 2.5468\n",
       "Epoch 73/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.5022 - mse: 5.5022 - mae: 1.6912 - val_loss: 17.6786 - val_mse: 17.6786 - val_mae: 2.7316\n",
+      "404/404 [==============================] - 0s 353us/sample - loss: 4.9266 - mse: 4.9266 - mae: 1.6260 - val_loss: 15.7831 - val_mse: 15.7831 - val_mae: 2.5469\n",
       "Epoch 74/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 5.2794 - mse: 5.2794 - mae: 1.6478 - val_loss: 17.6115 - val_mse: 17.6115 - val_mae: 2.6773\n",
+      "404/404 [==============================] - 0s 334us/sample - loss: 4.5020 - mse: 4.5020 - mae: 1.5255 - val_loss: 15.7124 - val_mse: 15.7124 - val_mae: 2.5349\n",
       "Epoch 75/75\n",
-      "404/404 [==============================] - 0s 338us/sample - loss: 5.4796 - mse: 5.4796 - mae: 1.6876 - val_loss: 17.2835 - val_mse: 17.2835 - val_mae: 2.7126\n"
+      "404/404 [==============================] - 0s 352us/sample - loss: 4.6304 - mse: 4.6304 - mae: 1.5642 - val_loss: 15.0736 - val_mse: 15.0736 - val_mae: 2.4870\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f36340c6b38>"
+       "<tensorflow.python.keras.callbacks.History at 0x7ff2c416bc18>"
       ]
      },
      "execution_count": 3,
@@ -439,7 +439,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 1,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -462,13 +462,13 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.65234375 using {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.65234375, Stdev: 0.033298728782667764 with: {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6263020833333334, Stdev: 0.01813592223591682 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6041666666666666, Stdev: 0.037782859709757574 with: {'batch_size': 40, 'epochs': 20}\n",
-      "Means: 0.5533854166666666, Stdev: 0.03210632293213009 with: {'batch_size': 60, 'epochs': 20}\n",
-      "Means: 0.61328125, Stdev: 0.024079742199097563 with: {'batch_size': 80, 'epochs': 20}\n",
-      "Means: 0.5611979166666666, Stdev: 0.038450060052691144 with: {'batch_size': 100, 'epochs': 20}\n"
+      "Best: 0.65625 using {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.65234375, Stdev: 0.01390244564066577 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.65625, Stdev: 0.008438464451051902 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.5716145833333334, Stdev: 0.012889967365379774 with: {'batch_size': 40, 'epochs': 20}\n",
+      "Means: 0.6015625, Stdev: 0.04521811290152432 with: {'batch_size': 60, 'epochs': 20}\n",
+      "Means: 0.6471354166666666, Stdev: 0.03194751079787838 with: {'batch_size': 80, 'epochs': 20}\n",
+      "Means: 0.5755208333333334, Stdev: 0.05378092819808173 with: {'batch_size': 100, 'epochs': 20}\n"
      ]
     }
    ],
@@ -541,7 +541,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 2,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -556,11 +556,11 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.7044270833333334 using {'batch_size': 20, 'epochs': 200}\n",
-      "Means: 0.6666666666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6588541666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 40}\n",
-      "Means: 0.6848958333333334, Stdev: 0.03498705427745938 with: {'batch_size': 20, 'epochs': 60}\n",
-      "Means: 0.7044270833333334, Stdev: 0.018414239093399672 with: {'batch_size': 20, 'epochs': 200}\n"
+      "Best: 0.7174479166666666 using {'batch_size': 20, 'epochs': 200}\n",
+      "Means: 0.6263020833333334, Stdev: 0.03513212907091677 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.6653645833333334, Stdev: 0.03962271889245557 with: {'batch_size': 20, 'epochs': 40}\n",
+      "Means: 0.640625, Stdev: 0.030425316264447715 with: {'batch_size': 20, 'epochs': 60}\n",
+      "Means: 0.7174479166666666, Stdev: 0.020505228838572424 with: {'batch_size': 20, 'epochs': 200}\n"
      ]
     }
    ],
@@ -720,36 +720,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 3,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "\n",
-       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro</a><br/>\n",
-       "            "
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "W&B Run: https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro"
-      ]
-     },
-     "execution_count": 6,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "import wandb\n",
     "from wandb.keras import WandbCallback"
@@ -774,7 +747,7 @@
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
        "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/30f7jjpy\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/30f7jjpy</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -790,111 +763,111 @@
      "text": [
       "Train on 270 samples, validate on 134 samples\n",
       "Epoch 1/50\n",
-      "270/270 [==============================] - 1s 3ms/sample - loss: 492.3539 - mse: 492.3539 - mae: 20.3197 - val_loss: 481.5445 - val_mse: 481.5445 - val_mae: 19.6138\n",
+      "270/270 [==============================] - 1s 3ms/sample - loss: 490.8816 - mse: 490.8817 - mae: 20.4225 - val_loss: 463.3583 - val_mse: 463.3582 - val_mae: 19.4308\n",
       "Epoch 2/50\n",
-      "270/270 [==============================] - 0s 591us/sample - loss: 239.4999 - mse: 239.4999 - mae: 12.8064 - val_loss: 113.8561 - val_mse: 113.8561 - val_mae: 8.2962\n",
+      "270/270 [==============================] - 0s 587us/sample - loss: 224.3275 - mse: 224.3275 - mae: 12.8177 - val_loss: 93.7189 - val_mse: 93.7189 - val_mae: 7.4271\n",
       "Epoch 3/50\n",
-      "270/270 [==============================] - 0s 618us/sample - loss: 56.2921 - mse: 56.2921 - mae: 5.8988 - val_loss: 62.7912 - val_mse: 62.7912 - val_mae: 5.6465\n",
+      "270/270 [==============================] - 0s 623us/sample - loss: 49.4094 - mse: 49.4094 - mae: 5.3485 - val_loss: 50.5440 - val_mse: 50.5440 - val_mae: 5.0884\n",
       "Epoch 4/50\n",
-      "270/270 [==============================] - 0s 613us/sample - loss: 29.4994 - mse: 29.4994 - mae: 3.9653 - val_loss: 37.9256 - val_mse: 37.9256 - val_mae: 4.1730\n",
+      "270/270 [==============================] - 0s 629us/sample - loss: 24.2660 - mse: 24.2660 - mae: 3.6847 - val_loss: 33.2632 - val_mse: 33.2632 - val_mae: 3.9261\n",
       "Epoch 5/50\n",
-      "270/270 [==============================] - 0s 608us/sample - loss: 20.6919 - mse: 20.6919 - mae: 3.3022 - val_loss: 31.7489 - val_mse: 31.7489 - val_mae: 3.7113\n",
+      "270/270 [==============================] - 0s 591us/sample - loss: 17.7696 - mse: 17.7696 - mae: 3.1332 - val_loss: 29.9609 - val_mse: 29.9609 - val_mae: 3.4952\n",
       "Epoch 6/50\n",
-      "270/270 [==============================] - 0s 602us/sample - loss: 17.2701 - mse: 17.2701 - mae: 3.0291 - val_loss: 27.3921 - val_mse: 27.3921 - val_mae: 3.4958\n",
+      "270/270 [==============================] - 0s 605us/sample - loss: 14.6718 - mse: 14.6718 - mae: 2.8170 - val_loss: 25.4843 - val_mse: 25.4843 - val_mae: 3.2592\n",
       "Epoch 7/50\n",
-      "270/270 [==============================] - 0s 671us/sample - loss: 15.5172 - mse: 15.5172 - mae: 2.8537 - val_loss: 25.3208 - val_mse: 25.3208 - val_mae: 3.3650\n",
+      "270/270 [==============================] - 0s 634us/sample - loss: 13.4302 - mse: 13.4302 - mae: 2.7306 - val_loss: 23.0510 - val_mse: 23.0510 - val_mae: 3.0794\n",
       "Epoch 8/50\n",
-      "270/270 [==============================] - 0s 661us/sample - loss: 13.7548 - mse: 13.7548 - mae: 2.7089 - val_loss: 23.8920 - val_mse: 23.8920 - val_mae: 3.2746\n",
+      "270/270 [==============================] - 0s 625us/sample - loss: 12.1769 - mse: 12.1769 - mae: 2.5880 - val_loss: 22.6795 - val_mse: 22.6795 - val_mae: 3.0183\n",
       "Epoch 9/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 12.3745 - mse: 12.3745 - mae: 2.5662 - val_loss: 22.1294 - val_mse: 22.1294 - val_mae: 3.1509\n",
+      "270/270 [==============================] - 0s 699us/sample - loss: 10.9682 - mse: 10.9682 - mae: 2.4646 - val_loss: 20.1932 - val_mse: 20.1932 - val_mae: 2.9101\n",
       "Epoch 10/50\n",
-      "270/270 [==============================] - 0s 614us/sample - loss: 11.2424 - mse: 11.2424 - mae: 2.4804 - val_loss: 20.5718 - val_mse: 20.5718 - val_mae: 3.0461\n",
+      "270/270 [==============================] - 0s 611us/sample - loss: 10.2239 - mse: 10.2239 - mae: 2.4109 - val_loss: 18.9364 - val_mse: 18.9364 - val_mae: 2.8439\n",
       "Epoch 11/50\n",
-      "270/270 [==============================] - 0s 605us/sample - loss: 10.6098 - mse: 10.6098 - mae: 2.4178 - val_loss: 20.3467 - val_mse: 20.3467 - val_mae: 3.0251\n",
+      "270/270 [==============================] - 0s 600us/sample - loss: 9.8642 - mse: 9.8642 - mae: 2.4013 - val_loss: 18.7510 - val_mse: 18.7510 - val_mae: 2.8276\n",
       "Epoch 12/50\n",
-      "270/270 [==============================] - 0s 576us/sample - loss: 10.0011 - mse: 10.0011 - mae: 2.3257 - val_loss: 18.4283 - val_mse: 18.4283 - val_mae: 2.8938\n",
+      "270/270 [==============================] - 0s 615us/sample - loss: 9.3630 - mse: 9.3630 - mae: 2.3451 - val_loss: 18.3309 - val_mse: 18.3309 - val_mae: 2.8186\n",
       "Epoch 13/50\n",
-      "270/270 [==============================] - 0s 666us/sample - loss: 9.1287 - mse: 9.1287 - mae: 2.2384 - val_loss: 18.2024 - val_mse: 18.2024 - val_mae: 2.9116\n",
+      "270/270 [==============================] - 0s 628us/sample - loss: 8.9273 - mse: 8.9273 - mae: 2.2780 - val_loss: 17.6864 - val_mse: 17.6864 - val_mae: 2.8456\n",
       "Epoch 14/50\n",
-      "270/270 [==============================] - 0s 603us/sample - loss: 8.6211 - mse: 8.6211 - mae: 2.1980 - val_loss: 17.4749 - val_mse: 17.4749 - val_mae: 2.8290\n",
+      "270/270 [==============================] - 0s 488us/sample - loss: 8.7314 - mse: 8.7314 - mae: 2.2720 - val_loss: 17.7294 - val_mse: 17.7294 - val_mae: 2.8289\n",
       "Epoch 15/50\n",
-      "270/270 [==============================] - 0s 463us/sample - loss: 8.4558 - mse: 8.4558 - mae: 2.2087 - val_loss: 17.7878 - val_mse: 17.7878 - val_mae: 2.8516\n",
+      "270/270 [==============================] - 0s 637us/sample - loss: 8.2788 - mse: 8.2788 - mae: 2.2043 - val_loss: 16.9805 - val_mse: 16.9805 - val_mae: 2.7709\n",
       "Epoch 16/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 8.3626 - mse: 8.3626 - mae: 2.2031 - val_loss: 16.7101 - val_mse: 16.7101 - val_mae: 2.7820\n",
+      "270/270 [==============================] - 0s 708us/sample - loss: 8.7452 - mse: 8.7452 - mae: 2.2514 - val_loss: 16.0394 - val_mse: 16.0394 - val_mae: 2.7251\n",
       "Epoch 17/50\n",
-      "270/270 [==============================] - 0s 607us/sample - loss: 7.9180 - mse: 7.9180 - mae: 2.1265 - val_loss: 16.6064 - val_mse: 16.6064 - val_mae: 2.7419\n",
+      "270/270 [==============================] - 0s 470us/sample - loss: 9.5037 - mse: 9.5037 - mae: 2.3140 - val_loss: 18.8845 - val_mse: 18.8845 - val_mae: 3.0215\n",
       "Epoch 18/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 7.5552 - mse: 7.5552 - mae: 2.0235 - val_loss: 17.2872 - val_mse: 17.2872 - val_mae: 2.8539\n",
+      "270/270 [==============================] - 0s 473us/sample - loss: 8.3578 - mse: 8.3578 - mae: 2.2097 - val_loss: 16.3183 - val_mse: 16.3183 - val_mae: 2.7635\n",
       "Epoch 19/50\n",
-      "270/270 [==============================] - 0s 616us/sample - loss: 7.0971 - mse: 7.0971 - mae: 2.0038 - val_loss: 16.5110 - val_mse: 16.5110 - val_mae: 2.8042\n",
+      "270/270 [==============================] - 0s 493us/sample - loss: 7.3974 - mse: 7.3974 - mae: 2.0955 - val_loss: 16.6346 - val_mse: 16.6346 - val_mae: 2.7770\n",
       "Epoch 20/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 6.7068 - mse: 6.7068 - mae: 1.9539 - val_loss: 15.5886 - val_mse: 15.5886 - val_mae: 2.7048\n",
+      "270/270 [==============================] - 0s 597us/sample - loss: 7.3424 - mse: 7.3424 - mae: 2.0823 - val_loss: 15.6754 - val_mse: 15.6754 - val_mae: 2.6837\n",
       "Epoch 21/50\n",
-      "270/270 [==============================] - 0s 461us/sample - loss: 6.8542 - mse: 6.8542 - mae: 1.9979 - val_loss: 17.2378 - val_mse: 17.2378 - val_mae: 2.8853\n",
+      "270/270 [==============================] - 0s 470us/sample - loss: 7.3840 - mse: 7.3840 - mae: 2.0749 - val_loss: 16.3104 - val_mse: 16.3104 - val_mae: 2.7602\n",
       "Epoch 22/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 6.5719 - mse: 6.5719 - mae: 1.9312 - val_loss: 16.3043 - val_mse: 16.3043 - val_mae: 2.7756\n",
+      "270/270 [==============================] - 0s 445us/sample - loss: 7.3790 - mse: 7.3790 - mae: 2.0953 - val_loss: 17.4050 - val_mse: 17.4050 - val_mae: 2.8738\n",
       "Epoch 23/50\n",
-      "270/270 [==============================] - 0s 478us/sample - loss: 6.6161 - mse: 6.6161 - mae: 1.9572 - val_loss: 15.7992 - val_mse: 15.7992 - val_mae: 2.7219\n",
+      "270/270 [==============================] - 0s 559us/sample - loss: 7.2687 - mse: 7.2687 - mae: 2.0496 - val_loss: 15.4371 - val_mse: 15.4371 - val_mae: 2.6716\n",
       "Epoch 24/50\n",
-      "270/270 [==============================] - 0s 491us/sample - loss: 7.1269 - mse: 7.1269 - mae: 2.0137 - val_loss: 16.5402 - val_mse: 16.5402 - val_mae: 2.8005\n",
+      "270/270 [==============================] - 0s 435us/sample - loss: 6.6650 - mse: 6.6650 - mae: 1.9651 - val_loss: 15.6032 - val_mse: 15.6032 - val_mae: 2.6776\n",
       "Epoch 25/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 6.3382 - mse: 6.3382 - mae: 1.8540 - val_loss: 16.5034 - val_mse: 16.5034 - val_mae: 2.7864\n",
+      "270/270 [==============================] - 0s 456us/sample - loss: 6.4503 - mse: 6.4503 - mae: 1.9052 - val_loss: 15.4885 - val_mse: 15.4885 - val_mae: 2.6739\n",
       "Epoch 26/50\n",
-      "270/270 [==============================] - 0s 488us/sample - loss: 5.9442 - mse: 5.9442 - mae: 1.8251 - val_loss: 15.6558 - val_mse: 15.6558 - val_mae: 2.7102\n",
+      "270/270 [==============================] - 0s 439us/sample - loss: 6.3433 - mse: 6.3433 - mae: 1.9063 - val_loss: 15.9618 - val_mse: 15.9618 - val_mae: 2.6966\n",
       "Epoch 27/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 5.5832 - mse: 5.5832 - mae: 1.7432 - val_loss: 15.3021 - val_mse: 15.3021 - val_mae: 2.6862\n",
+      "270/270 [==============================] - 0s 430us/sample - loss: 6.1725 - mse: 6.1725 - mae: 1.8775 - val_loss: 15.7322 - val_mse: 15.7322 - val_mae: 2.7155\n",
       "Epoch 28/50\n",
-      "270/270 [==============================] - 0s 436us/sample - loss: 5.4530 - mse: 5.4530 - mae: 1.7354 - val_loss: 15.4570 - val_mse: 15.4570 - val_mae: 2.6846\n",
+      "270/270 [==============================] - 0s 440us/sample - loss: 6.1726 - mse: 6.1726 - mae: 1.8712 - val_loss: 15.5335 - val_mse: 15.5335 - val_mae: 2.6662\n",
       "Epoch 29/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 5.3070 - mse: 5.3070 - mae: 1.7079 - val_loss: 15.8510 - val_mse: 15.8510 - val_mae: 2.7644\n",
+      "270/270 [==============================] - 0s 603us/sample - loss: 6.1123 - mse: 6.1123 - mae: 1.8459 - val_loss: 15.2890 - val_mse: 15.2890 - val_mae: 2.6496\n",
       "Epoch 30/50\n",
-      "270/270 [==============================] - 0s 477us/sample - loss: 5.4157 - mse: 5.4157 - mae: 1.7321 - val_loss: 15.9160 - val_mse: 15.9160 - val_mae: 2.7134\n",
+      "270/270 [==============================] - 0s 458us/sample - loss: 5.7772 - mse: 5.7772 - mae: 1.7984 - val_loss: 15.7658 - val_mse: 15.7658 - val_mae: 2.7018\n",
       "Epoch 31/50\n",
-      "270/270 [==============================] - 0s 452us/sample - loss: 5.2639 - mse: 5.2639 - mae: 1.6981 - val_loss: 15.3554 - val_mse: 15.3554 - val_mae: 2.6662\n",
+      "270/270 [==============================] - 0s 593us/sample - loss: 5.8648 - mse: 5.8648 - mae: 1.8293 - val_loss: 15.1814 - val_mse: 15.1814 - val_mae: 2.6341\n",
       "Epoch 32/50\n",
-      "270/270 [==============================] - 0s 475us/sample - loss: 5.7687 - mse: 5.7687 - mae: 1.8045 - val_loss: 15.7151 - val_mse: 15.7151 - val_mae: 2.6867\n",
+      "270/270 [==============================] - 0s 584us/sample - loss: 5.6753 - mse: 5.6753 - mae: 1.7654 - val_loss: 14.9292 - val_mse: 14.9292 - val_mae: 2.6238\n",
       "Epoch 33/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 5.5210 - mse: 5.5210 - mae: 1.7367 - val_loss: 15.4227 - val_mse: 15.4227 - val_mae: 2.6561\n",
+      "270/270 [==============================] - 0s 468us/sample - loss: 5.4260 - mse: 5.4260 - mae: 1.7677 - val_loss: 15.7692 - val_mse: 15.7692 - val_mae: 2.6781\n",
       "Epoch 34/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 5.5663 - mse: 5.5663 - mae: 1.7294 - val_loss: 15.3376 - val_mse: 15.3376 - val_mae: 2.6991\n",
+      "270/270 [==============================] - 0s 466us/sample - loss: 5.4490 - mse: 5.4490 - mae: 1.7424 - val_loss: 15.0336 - val_mse: 15.0336 - val_mae: 2.6390\n",
       "Epoch 35/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 5.0063 - mse: 5.0063 - mae: 1.6196 - val_loss: 15.2642 - val_mse: 15.2642 - val_mae: 2.6796\n",
+      "270/270 [==============================] - 0s 453us/sample - loss: 5.1606 - mse: 5.1606 - mae: 1.6810 - val_loss: 15.5521 - val_mse: 15.5521 - val_mae: 2.7373\n",
       "Epoch 36/50\n",
-      "270/270 [==============================] - 0s 459us/sample - loss: 4.7251 - mse: 4.7251 - mae: 1.5727 - val_loss: 15.4858 - val_mse: 15.4858 - val_mae: 2.7288\n",
+      "270/270 [==============================] - 0s 449us/sample - loss: 5.7277 - mse: 5.7277 - mae: 1.7884 - val_loss: 14.9733 - val_mse: 14.9733 - val_mae: 2.6227\n",
       "Epoch 37/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 4.6394 - mse: 4.6394 - mae: 1.5854 - val_loss: 15.1139 - val_mse: 15.1139 - val_mae: 2.6305\n",
+      "270/270 [==============================] - 0s 648us/sample - loss: 5.1312 - mse: 5.1312 - mae: 1.6914 - val_loss: 14.5718 - val_mse: 14.5718 - val_mae: 2.5711\n",
       "Epoch 38/50\n",
-      "270/270 [==============================] - 0s 592us/sample - loss: 4.5669 - mse: 4.5669 - mae: 1.5548 - val_loss: 14.9898 - val_mse: 14.9898 - val_mae: 2.6340\n",
+      "270/270 [==============================] - 0s 514us/sample - loss: 4.8918 - mse: 4.8918 - mae: 1.6636 - val_loss: 15.0902 - val_mse: 15.0902 - val_mae: 2.6500\n",
       "Epoch 39/50\n",
-      "270/270 [==============================] - 0s 458us/sample - loss: 4.4480 - mse: 4.4480 - mae: 1.5334 - val_loss: 15.6389 - val_mse: 15.6389 - val_mae: 2.7337\n",
+      "270/270 [==============================] - 0s 456us/sample - loss: 5.3422 - mse: 5.3422 - mae: 1.7549 - val_loss: 15.2631 - val_mse: 15.2631 - val_mae: 2.6461\n",
       "Epoch 40/50\n",
-      "270/270 [==============================] - 0s 455us/sample - loss: 4.4119 - mse: 4.4119 - mae: 1.5426 - val_loss: 15.0723 - val_mse: 15.0723 - val_mae: 2.6709\n",
+      "270/270 [==============================] - 0s 468us/sample - loss: 4.9070 - mse: 4.9070 - mae: 1.6893 - val_loss: 14.9719 - val_mse: 14.9719 - val_mae: 2.6363\n",
       "Epoch 41/50\n",
-      "270/270 [==============================] - 0s 473us/sample - loss: 4.0797 - mse: 4.0797 - mae: 1.4725 - val_loss: 15.4706 - val_mse: 15.4706 - val_mae: 2.6707\n",
+      "270/270 [==============================] - 0s 495us/sample - loss: 4.8164 - mse: 4.8164 - mae: 1.6160 - val_loss: 14.9441 - val_mse: 14.9441 - val_mae: 2.5800\n",
       "Epoch 42/50\n",
-      "270/270 [==============================] - 0s 449us/sample - loss: 4.0619 - mse: 4.0619 - mae: 1.4692 - val_loss: 15.2423 - val_mse: 15.2423 - val_mae: 2.6165\n",
+      "270/270 [==============================] - 0s 497us/sample - loss: 4.7492 - mse: 4.7492 - mae: 1.6444 - val_loss: 15.9035 - val_mse: 15.9035 - val_mae: 2.7250\n",
       "Epoch 43/50\n",
-      "270/270 [==============================] - 0s 465us/sample - loss: 4.1861 - mse: 4.1861 - mae: 1.5076 - val_loss: 15.7510 - val_mse: 15.7510 - val_mae: 2.7279\n",
+      "270/270 [==============================] - 0s 486us/sample - loss: 4.9941 - mse: 4.9941 - mae: 1.6588 - val_loss: 14.8297 - val_mse: 14.8297 - val_mae: 2.5949\n",
       "Epoch 44/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 4.1128 - mse: 4.1128 - mae: 1.4810 - val_loss: 15.4814 - val_mse: 15.4814 - val_mae: 2.6562\n",
+      "270/270 [==============================] - 0s 467us/sample - loss: 4.6100 - mse: 4.6100 - mae: 1.6015 - val_loss: 14.7418 - val_mse: 14.7419 - val_mae: 2.5882\n",
       "Epoch 45/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 4.2171 - mse: 4.2171 - mae: 1.5205 - val_loss: 16.3839 - val_mse: 16.3839 - val_mae: 2.8194\n",
+      "270/270 [==============================] - 0s 493us/sample - loss: 4.8405 - mse: 4.8405 - mae: 1.6775 - val_loss: 15.6624 - val_mse: 15.6624 - val_mae: 2.6978\n",
       "Epoch 46/50\n",
-      "270/270 [==============================] - 0s 422us/sample - loss: 4.2609 - mse: 4.2609 - mae: 1.5548 - val_loss: 15.3587 - val_mse: 15.3587 - val_mae: 2.7161\n",
+      "270/270 [==============================] - 0s 628us/sample - loss: 4.2125 - mse: 4.2125 - mae: 1.5151 - val_loss: 14.3445 - val_mse: 14.3445 - val_mae: 2.5518\n",
       "Epoch 47/50\n",
-      "270/270 [==============================] - 0s 454us/sample - loss: 4.4635 - mse: 4.4635 - mae: 1.5440 - val_loss: 15.7736 - val_mse: 15.7736 - val_mae: 2.7184\n",
+      "270/270 [==============================] - 0s 461us/sample - loss: 4.4944 - mse: 4.4945 - mae: 1.5634 - val_loss: 14.3783 - val_mse: 14.3783 - val_mae: 2.5514\n",
       "Epoch 48/50\n",
-      "270/270 [==============================] - 0s 426us/sample - loss: 3.7406 - mse: 3.7406 - mae: 1.4147 - val_loss: 15.6718 - val_mse: 15.6718 - val_mae: 2.7468\n",
+      "270/270 [==============================] - 0s 478us/sample - loss: 4.0947 - mse: 4.0947 - mae: 1.5113 - val_loss: 14.8048 - val_mse: 14.8048 - val_mae: 2.6123\n",
       "Epoch 49/50\n",
-      "270/270 [==============================] - 0s 445us/sample - loss: 3.6173 - mse: 3.6173 - mae: 1.3816 - val_loss: 15.7291 - val_mse: 15.7291 - val_mae: 2.7789\n",
+      "270/270 [==============================] - 0s 484us/sample - loss: 4.0376 - mse: 4.0376 - mae: 1.4877 - val_loss: 14.4594 - val_mse: 14.4594 - val_mae: 2.5584\n",
       "Epoch 50/50\n",
-      "270/270 [==============================] - 0s 430us/sample - loss: 3.6303 - mse: 3.6303 - mae: 1.4266 - val_loss: 15.4937 - val_mse: 15.4937 - val_mae: 2.7390\n"
+      "270/270 [==============================] - 0s 497us/sample - loss: 4.0920 - mse: 4.0920 - mae: 1.4953 - val_loss: 15.8213 - val_mse: 15.8213 - val_mae: 2.7546\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f315c319be0>"
+       "<tensorflow.python.keras.callbacks.History at 0x7feb1e531780>"
       ]
      },
      "execution_count": 8,
@@ -985,15 +958,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 10,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: huau0u9r\n",
-      "Sweep URL: https://app.wandb.ai/lambda-ds7/boston/sweeps/huau0u9r\n"
+      "Create sweep with ID: w55nffki\n",
+      "Sweep URL: https://app.wandb.ai/lambda-ds7/boston/sweeps/w55nffki\n"
      ]
     }
    ],
